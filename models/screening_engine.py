import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
import time
import json
from datetime import datetime
import os

class HuggingFaceScreeningEngine:
    """HuggingFace-only resume screening engine using free inference API for all tasks"""
    
    def __init__(self):
        from config import SCORING_WEIGHTS, MIN_SCORE_THRESHOLD, TOP_CANDIDATES
        
        # Initialize components
        self.scoring_weights = SCORING_WEIGHTS
        self.min_threshold = MIN_SCORE_THRESHOLD
        self.top_candidates = TOP_CANDIDATES
        
        # Initialize HuggingFace manager and parser
        self.huggingface_manager = None
        self.parser = None
        
        # Results storage
        self.last_analysis_results = None
        self.processing_stats = {
            'total_resumes_processed': 0,
            'total_processing_time': 0,
            'avg_processing_time': 0,
            'huggingface_calls': 0,
            'huggingface_errors': 0,
            'successful_extractions': 0,
            'successful_scores': 0,
            'rate_limit_hits': 0
        }
    
    def _initialize_components(self):
        """Lazy initialization of components"""
        if self.huggingface_manager is None:
            from models.llm_manager import HuggingFaceLLMManager
            self.huggingface_manager = HuggingFaceLLMManager()
        
        if self.parser is None:
            from parser import ResumeParser
            self.parser = ResumeParser()
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        self._initialize_components()
        
        hf_status = self.huggingface_manager.get_status()
        
        return {
            'deployment_type': 'ü§ó HuggingFace Only (FREE)',
            'huggingface_status': hf_status,
            'parser_status': {'available': True, 'type': 'Resume Parser'},
            'processing_stats': self.processing_stats.copy(),
            'ready_for_screening': hf_status.get('connection_status', {}).get('connected', False),
            'model_info': self._get_model_summary(),
            'rate_limits': 'Free tier: ~10 requests/minute per model'
        }
    
    def _get_model_summary(self) -> Dict[str, str]:
        """Get summary of active models"""
        return {
            'data_extraction': 'Mistral 7B Instruct (HuggingFace)',
            'relevance_scoring': 'Mistral 7B Instruct (HuggingFace)',
            'detailed_analysis': 'Mistral 7B Instruct (HuggingFace)',
            'chatbot': 'Mistral 7B Instruct (HuggingFace)',
            'cost': 'FREE with rate limits',
            'advantages': 'Open source, privacy-focused, community-driven'
        }
    
    def process_single_resume(self, file_path: str, filename: str, job_description: str = "") -> Dict[str, Any]:
        """Process a single resume with HuggingFace-only analysis"""
        self._initialize_components()
        
        start_time = time.time()
        
        result = {
            'filename': filename,
            'status': 'processing',
            'scores': {},
            'analysis': {},
            'error': None,
            'processing_time': 0,
            'huggingface_calls': 0
        }
        
        try:
            # Step 1: Parse resume text
            with st.spinner(f"üìÑ Parsing {filename}..."):
                parsed_data = self.parser.parse_resume(file_path, filename)
                
                if not parsed_data.get('success', False):
                    result['status'] = 'failed'
                    result['error'] = parsed_data.get('error', 'Parsing failed')
                    return result
                
                resume_text = parsed_data.get('cleaned_text', '')
                if not resume_text:
                    result['status'] = 'failed'
                    result['error'] = 'No text extracted from resume'
                    return result
            
            # Step 2: Extract structured data using HuggingFace LLM
            with st.spinner("ü§ó Extracting data with HuggingFace..."):
                extraction_result = self.huggingface_manager.extract_resume_data(resume_text)
                result['huggingface_calls'] += 1
                self.processing_stats['huggingface_calls'] += 1
                
                if not extraction_result['success']:
                    # Fallback to basic extraction
                    extracted_data = self._create_fallback_data(resume_text)
                    st.warning("‚ö†Ô∏è Using basic extraction due to HuggingFace error")
                else:
                    extracted_data = extraction_result['data']
                    self.processing_stats['successful_extractions'] += 1
            
            # Step 3: Score relevance using HuggingFace LLM
            relevance_score = 0.0
            relevance_analysis = {}
            
            if job_description:
                with st.spinner("üéØ Scoring relevance with HuggingFace..."):
                    scoring_result = self.huggingface_manager.score_relevance(
                        job_description, 
                        {'data': extracted_data}
                    )
                    result['huggingface_calls'] += 1
                    self.processing_stats['huggingface_calls'] += 1
                    
                    if scoring_result['success']:
                        relevance_score = scoring_result['score']
                        relevance_analysis = scoring_result['analysis']
                        self.processing_stats['successful_scores'] += 1
                    else:
                        st.warning("‚ö†Ô∏è Relevance scoring failed, using keyword-based score")
                        relevance_score = self._calculate_keyword_score(job_description, extracted_data)
            
            # Step 4: Calculate experience and skills scores (local processing)
            experience_score = self._calculate_experience_score(extracted_data)
            skills_score = self._calculate_skills_score(extracted_data, job_description)
            
            # Step 5: Calculate composite score
            composite_score = (
                self.scoring_weights['relevance_score'] * relevance_score +
                self.scoring_weights['experience_match'] * experience_score +
                self.scoring_weights['skills_match'] * skills_score
            )
            
            # Step 6: Generate detailed analysis for high-scoring candidates
            detailed_analysis = ""
            if composite_score > 0.5 and job_description:
                with st.spinner("üìä Generating detailed analysis..."):
                    analysis_result = self.huggingface_manager.generate_detailed_analysis(
                        "Position", job_description, {'data': extracted_data}
                    )
                    result['huggingface_calls'] += 1
                    self.processing_stats['huggingface_calls'] += 1
                    
                    if analysis_result['success']:
                        detailed_analysis = analysis_result['analysis']
            
            # Compile comprehensive results
            result.update({
                'status': 'completed',
                'scores': {
                    'composite_score': round(composite_score, 3),
                    'relevance_score': round(relevance_score, 3),
                    'experience_score': round(experience_score, 3),
                    'skills_score': round(skills_score, 3),
                    'breakdown': {
                        'relevance_weight': self.scoring_weights['relevance_score'],
                        'experience_weight': self.scoring_weights['experience_match'],
                        'skills_weight': self.scoring_weights['skills_match']
                    }
                },
                'analysis': {
                    'extracted_data': extracted_data,
                    'relevance_analysis': relevance_analysis,
                    'detailed_analysis': detailed_analysis,
                    'candidate_summary': self._create_candidate_summary(extracted_data),
                    'key_highlights': self._extract_key_highlights(extracted_data),
                    'processing_method': 'HuggingFace LLM (Free Tier)',
                    'models_used': self._get_models_used()
                },
                'processing_time': time.time() - start_time
            })
            
            # Update global stats
            self.processing_stats['total_resumes_processed'] += 1
            self.processing_stats['total_processing_time'] += result['processing_time']
            self.processing_stats['avg_processing_time'] = (
                self.processing_stats['total_processing_time'] / 
                self.processing_stats['total_resumes_processed']
            )
            
        except Exception as e:
            result.update({
                'status': 'error',
                'error': str(e),
                'processing_time': time.time() - start_time
            })
            st.error(f"‚ùå Error processing {filename}: {e}")
            self.processing_stats['huggingface_errors'] += result['huggingface_calls']
        
        return result
    
    def process_multiple_resumes(self, uploaded_files: List, job_description: str = "") -> Dict[str, Any]:
        """Process multiple resumes using HuggingFace free inference"""
        self._initialize_components()
        
        if not uploaded_files:
            return {'error': 'No files uploaded', 'results': []}
        
        total_start_time = time.time()
        results = []
        
        # Progress tracking
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Display system status
        system_status = self.get_system_status()
        with st.expander("üîß System Status", expanded=False):
            if system_status['ready_for_screening']:
                st.success("‚úÖ HuggingFace Free API Ready")
                st.info(f"Using: {system_status['model_info']['data_extraction']}")
                st.warning("‚è∞ Rate limits apply: ~10 requests/minute per model")
            else:
                st.error("‚ùå HuggingFace not ready - check API token")
                return {'error': 'System not ready', 'results': []}
        
        # Rate limiting awareness
        if len(uploaded_files) > 10:
            st.warning(f"‚ö†Ô∏è Processing {len(uploaded_files)} files. This may take time due to free tier rate limits.")
            st.info("üí° Consider upgrading to HuggingFace Pro for faster processing")
        
        for i, uploaded_file in enumerate(uploaded_files):
            # Update progress
            progress = (i + 1) / len(uploaded_files)
            progress_bar.progress(progress)
            status_text.text(f"Processing {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
            
            try:
                # Save uploaded file temporarily
                temp_path = self._save_temp_file(uploaded_file)
                
                # Process resume with HuggingFace
                result = self.process_single_resume(temp_path, uploaded_file.name, job_description)
                results.append(result)
                
                # Clean up temp file
                os.remove(temp_path)
                
                # Show individual result
                if result['status'] == 'completed':
                    score = result['scores']['composite_score']
                    st.write(f"‚úÖ {uploaded_file.name}: Score {score:.2f}")
                else:
                    st.write(f"‚ùå {uploaded_file.name}: {result.get('error', 'Failed')}")
                
                # Rate limiting: Small delay between requests
                if i < len(uploaded_files) - 1:  # Not the last file
                    time.sleep(1)  # 1 second delay to be nice to free API
                
            except Exception as e:
                st.error(f"Failed to process {uploaded_file.name}: {e}")
                results.append({
                    'filename': uploaded_file.name,
                    'status': 'error',
                    'error': str(e),
                    'scores': {},
                    'analysis': {},
                    'huggingface_calls': 0
                })
        
        # Clear progress indicators
        progress_bar.empty()
        status_text.empty()
        
        # Sort and rank results
        successful_results = [r for r in results if r['status'] == 'completed']
        successful_results.sort(
            key=lambda x: x['scores'].get('composite_score', 0), 
            reverse=True
        )
        
        # Add rankings
        for i, result in enumerate(successful_results):
            result['rank'] = i + 1
        
        # Calculate HuggingFace usage summary
        total_hf_calls = sum(r.get('huggingface_calls', 0) for r in results)
        
        # Compile comprehensive summary
        summary = {
            'total_processed': len(results),
            'successful': len(successful_results),
            'failed': len(results) - len(successful_results),
            'avg_composite_score': np.mean([
                r['scores'].get('composite_score', 0) 
                for r in successful_results
            ]) if successful_results else 0,
            'score_distribution': self._calculate_score_distribution(successful_results),
            'top_candidates': successful_results[:self.top_candidates],
            'processing_time': time.time() - total_start_time,
            'huggingface_calls': total_hf_calls,
            'system_status': system_status,
            'huggingface_performance': {
                'total_calls': total_hf_calls,
                'successful_extractions': self.processing_stats['successful_extractions'],
                'successful_scores': self.processing_stats['successful_scores'],
                'rate_limit_hits': self.processing_stats['rate_limit_hits'],
                'error_rate': self.processing_stats['huggingface_errors'] / max(total_hf_calls, 1),
                'avg_processing_time': self.processing_stats['avg_processing_time'],
                'cost': 'FREE (with rate limits)'
            }
        }
        
        # Store results for export
        self.last_analysis_results = {
            'results': results,
            'successful_results': successful_results,
            'summary': summary,
            'job_description': job_description,
            'timestamp': datetime.now().isoformat(),
            'huggingface_only': True
        }
        
        return {
            'results': successful_results,
            'failed_results': [r for r in results if r['status'] != 'completed'],
            'summary': summary,
            'huggingface_insights': self._generate_huggingface_insights(successful_results)
        }
    
    def _create_fallback_data(self, resume_text: str) -> Dict[str, Any]:
        """Create fallback structured data when LLM extraction fails"""
        # Basic keyword-based extraction
        text_lower = resume_text.lower()
        
        # Extract years of experience
        import re
        exp_matches = re.findall(r'(\d+)\s*(?:years?|yrs?)', text_lower)
        experience_years = max([int(x) for x in exp_matches], default=0) if exp_matches else 0
        
        # Extract basic skills
        skill_keywords = ['python', 'java', 'javascript', 'sql', 'react', 'node', 'aws', 'azure', 'docker']
        skills = [skill for skill in skill_keywords if skill in text_lower]
        
        # Extract email
        email_match = re.search(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', resume_text)
        email = email_match.group() if email_match else ""
        
        return {
            'name': 'Candidate',
            'email': email,
            'phone': '',
            'experience_years': experience_years,
            'current_role': 'Not specified',
            'skills': skills,
            'education': 'Not specified',
            'companies': [],
            'summary': resume_text[:200] + '...' if len(resume_text) > 200 else resume_text
        }
    
    def _calculate_keyword_score(self, job_description: str, extracted_data: Dict[str, Any]) -> float:
        """Calculate keyword-based relevance score as fallback"""
        if not job_description or not extracted_data.get('skills'):
            return 0.3
        
        job_desc_lower = job_description.lower()
        candidate_skills = [skill.lower() for skill in extracted_data.get('skills', [])]
        
        # Count skill matches
        matches = sum(1 for skill in candidate_skills if skill in job_desc_lower)
        
        # Calculate score
        if len(candidate_skills) > 0:
            match_ratio = matches / len(candidate_skills)
            return min(0.8, match_ratio * 1.2)  # Cap at 0.8 for keyword-only matching
        
        return 0.3
    
    def _calculate_experience_score(self, extracted_data: Dict[str, Any]) -> float:
        """Calculate experience score based on extracted data"""
        try:
            years_exp = extracted_data.get('experience_years', 0)
            
            # Experience scoring
            if years_exp >= 10:
                return 1.0
            elif years_exp >= 7:
                return 0.9
            elif years_exp >= 5:
                return 0.8
            elif years_exp >= 3:
                return 0.7
            elif years_exp >= 2:
                return 0.6
            elif years_exp >= 1:
                return 0.5
            else:
                return 0.3
                
        except:
            return 0.4  # Default score
    
    def _calculate_skills_score(self, extracted_data: Dict[str, Any], job_description: str) -> float:
        """Calculate skills matching score"""
        try:
            skills = extracted_data.get('skills', [])
            if not skills or not job_description:
                return 0.3
            
            job_desc_lower = job_description.lower()
            skills_lower = [skill.lower() for skill in skills]
            
            # Count skill matches in job description
            matches = sum(1 for skill in skills_lower if skill in job_desc_lower)
            
            # Calculate score based on match percentage
            if len(skills) > 0:
                match_ratio = matches / len(skills)
                return min(1.0, match_ratio * 1.3)  # Slight boost
            
            return 0.3
            
        except:
            return 0.3  # Default score
    
    def _calculate_score_distribution(self, results: List[Dict]) -> Dict[str, Any]:
        """Calculate score distribution statistics"""
        if not results:
            return {}
        
        scores = [r['scores']['composite_score'] for r in results]
        
        return {
            'mean': round(np.mean(scores), 3),
            'median': round(np.median(scores), 3),
            'std': round(np.std(scores), 3),
            'min': round(min(scores), 3),
            'max': round(max(scores), 3),
            'quartiles': {
                'q1': round(np.percentile(scores, 25), 3),
                'q3': round(np.percentile(scores, 75), 3)
            }
        }
    
    def _generate_huggingface_insights(self, results: List[Dict]) -> Dict[str, Any]:
        """Generate insights from HuggingFace analysis"""
        if not results:
            return {}
        
        insights = {
            'huggingface_performance': {},
            'quality_indicators': {},
            'processing_insights': {},
            'rate_limiting': {}
        }
        
        try:
            # Analyze HuggingFace performance
            total_results = len(results)
            successful_extractions = sum(
                1 for r in results 
                if r['analysis'].get('extracted_data', {}).get('name') != 'Candidate'
            )
            
            successful_analyses = sum(
                1 for r in results 
                if r['analysis'].get('detailed_analysis', '')
            )
            
            insights['huggingface_performance'] = {
                'extraction_success_rate': round(successful_extractions / total_results, 3),
                'analysis_success_rate': round(successful_analyses / total_results, 3),
                'overall_reliability': 'Good' if successful_extractions / total_results > 0.7 else 'Fair',
                'avg_processing_time': round(np.mean([r.get('processing_time', 0) for r in results]), 2),
                'cost_analysis': 'FREE - No charges incurred'
            }
            
            # Rate limiting insights
            insights['rate_limiting'] = {
                'hits_detected': self.processing_stats['rate_limit_hits'],
                'recommended_batch_size': '5-10 resumes at a time',
                'processing_strategy': 'Small batches with delays',
                'upgrade_suggestion': 'Consider HuggingFace Pro for higher limits'
            }
            
            # Quality indicators
            insights['quality_indicators'] = {
                'structured_extraction': 'Good' if successful_extractions / total_results > 0.8 else 'Fair',
                'analysis_coverage': f"{round(successful_analyses / total_results * 100)}%",
                'consistency': 'Good - Open source model reliability',
                'privacy': 'Excellent - No data stored by HuggingFace'
            }
            
        except Exception as e:
            insights['error'] = str(e)
        
        return insights
    
    def _create_candidate_summary(self, extracted_data: Dict[str, Any]) -> str:
        """Create a brief candidate summary"""
        name = extracted_data.get('name', 'Candidate')
        years = extracted_data.get('experience_years', 0)
        skills = extracted_data.get('skills', [])[:5]  # Top 5 skills
        role = extracted_data.get('current_role', '')
        
        summary = f"{name} - {years} years experience"
        if role and role != 'Not specified':
            summary += f" | {role}"
        if skills:
            summary += f" | Skills: {', '.join(skills)}"
            
        return summary
    
    def _extract_key_highlights(self, extracted_data: Dict[str, Any]) -> List[str]:
        """Extract key highlights from candidate data"""
        highlights = []
        
        # Experience highlights
        years = extracted_data.get('experience_years', 0)
        if years > 0:
            highlights.append(f"{years} years of experience")
        
        # Skills highlights
        skills = extracted_data.get('skills', [])
        if len(skills) > 3:
            highlights.append(f"Proficient in {len(skills)} technologies")
        
        # Education highlights
        education = extracted_data.get('education', '')
        if education and education != 'Not specified':
            highlights.append(f"Education: {education}")
        
        # Companies highlights
        companies = extracted_data.get('companies', [])
        if companies:
            highlights.append(f"Worked at {len(companies)} companies")
        
        return highlights[:4]  # Top 4 highlights
    
    def _get_models_used(self) -> Dict[str, str]:
        """Get information about models used"""
        return {
            'data_extraction': 'mistralai/Mistral-7B-Instruct-v0.1',
            'relevance_scoring': 'mistralai/Mistral-7B-Instruct-v0.1',
            'detailed_analysis': 'mistralai/Mistral-7B-Instruct-v0.1',
            'chatbot': 'mistralai/Mistral-7B-Instruct-v0.1',
            'provider': 'HuggingFace Inference API (Free)',
            'cost': 'FREE with rate limits'
        }
    
    def _save_temp_file(self, uploaded_file) -> str:
        """Save uploaded file temporarily"""
        temp_dir = "./data/temp_uploads"
        os.makedirs(temp_dir, exist_ok=True)
        
        temp_path = os.path.join(temp_dir, uploaded_file.name)
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        return temp_path
    
    def export_results_to_csv(self) -> Optional[str]:
        """Export HuggingFace analysis results to CSV"""
        if not self.last_analysis_results:
            return None
        
        try:
            results = self.last_analysis_results['successful_results']
            
            # Prepare enhanced CSV data
            csv_data = []
            for result in results:
                scores = result.get('scores', {})
                analysis = result.get('analysis', {})
                extracted_data = analysis.get('extracted_data', {})
                
                row = {
                    'Rank': result.get('rank', ''),
                    'Filename': result['filename'],
                    'Candidate_Name': extracted_data.get('name', 'Unknown'),
                    'Composite_Score': scores.get('composite_score', 0),
                    'Relevance_Score': scores.get('relevance_score', 0),
                    'Experience_Score': scores.get('experience_score', 0),
                    'Skills_Score': scores.get('skills_score', 0),
                    'Years_Experience': extracted_data.get('experience_years', 0),
                    'Top_Skills': ', '.join(extracted_data.get('skills', [])[:5]),
                    'Current_Role': extracted_data.get('current_role', 'N/A'),
                    'Email': extracted_data.get('email', 'N/A'),
                    'Processing_Time_s': round(result.get('processing_time', 0), 2),
                    'HuggingFace_Calls': result.get('huggingface_calls', 0),
                    'Processing_Method': 'HuggingFace Free API',
                    'Models_Used': 'Mistral 7B Instruct',
                    'Cost': 'FREE',
                    'Analysis_Available': 'Yes' if analysis.get('detailed_analysis') else 'No'
                }
                csv_data.append(row)
            
            # Create DataFrame and save
            df = pd.DataFrame(csv_data)
            csv_path = f"./data/huggingface_resume_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            df.to_csv(csv_path, index=False)
            
            return csv_path
            
        except Exception as e:
            st.error(f"CSV export failed: {e}")
            return None
    
    def get_analysis_summary(self) -> Optional[Dict[str, Any]]:
        """Get enhanced summary of last analysis"""
        if not self.last_analysis_results:
            return None
        
        summary = self.last_analysis_results['summary'].copy()
        summary['huggingface_advantages'] = {
            'cost': 'Completely FREE with HuggingFace account',
            'privacy': 'Open source models - no data retention',
            'transparency': 'Full model code and weights available',
            'community': 'Community-driven improvements',
            'flexibility': 'Can run locally later for full privacy',
            'no_vendor_lock': 'No dependency on proprietary APIs'
        }
        
        return summary
    
    def clear_cache(self):
        """Clear HuggingFace cache"""
        self._initialize_components()
        
        try:
            self.huggingface_manager.clear_cache()
            st.success("‚úÖ HuggingFace cache cleared")
        except Exception as e:
            st.error(f"‚ùå Cache clearing failed: {e}")
    
    def run_diagnostics(self) -> Dict[str, Any]:
        """Run comprehensive system diagnostics"""
        self._initialize_components()
        
        try:
            diagnostics = self.huggingface_manager.run_diagnostics()
            diagnostics.update({
                'system_type': 'HuggingFace Only (Free Inference API)',
                'processing_stats': self.processing_stats,
                'system_status': self.get_system_status(),
                'rate_limit_guidance': {
                    'current_hits': self.processing_stats['rate_limit_hits'],
                    'recommended_delay': '1-2 seconds between requests',
                    'batch_size': 'Process 5-10 resumes at a time',
                    'upgrade_benefit': 'HuggingFace Pro removes rate limits'
                }
            })
            
            # Overall health score
            health_score = 0
            if diagnostics.get('connection_test', {}).get('connected', False):
                health_score += 40
            
            model_tests = diagnostics.get('model_tests', {})
            working_models = sum(1 for test in model_tests.values() if test.get('status') == 'available')
            health_score += (working_models / len(model_tests)) * 40 if model_tests else 0
            
            # Rate limiting penalty
            if self.processing_stats['rate_limit_hits'] > 10:
                health_score -= 10
            
            health_score += 20  # Bonus for free tier
            
            diagnostics['overall_health'] = {
                'score': round(health_score),
                'rating': 'Excellent' if health_score >= 85 else 'Good' if health_score >= 70 else 'Fair',
                'huggingface_advantage': 'FREE tier with excellent open-source models'
            }
            
            return diagnostics
            
        except Exception as e:
            return {
                'error': str(e),
                'diagnostics_failed': True,
                'system_type': 'HuggingFace Only'
            }
    
    def get_cost_estimates(self, num_resumes: int) -> Dict[str, Any]:
        """Get HuggingFace cost estimates (FREE!)"""
        # HuggingFace calls per resume
        calls_per_resume = {
            'data_extraction': 1,      # Extract structured data
            'relevance_scoring': 1,    # Score relevance
            'detailed_analysis': 0.7,  # Only for high-scoring candidates
            'total_calls': 2.7
        }
        
        total_calls = calls_per_resume['total_calls'] * num_resumes
        
        # Rate limit calculations
        calls_per_minute = 10  # Conservative estimate for free tier
        estimated_time_minutes = total_calls / calls_per_minute
        
        return {
            'num_resumes': num_resumes,
            'calls_breakdown': {
                'data_extraction': int(calls_per_resume['data_extraction'] * num_resumes),
                'relevance_scoring': int(calls_per_resume['relevance_scoring'] * num_resumes),
                'detailed_analysis': int(calls_per_resume['detailed_analysis'] * num_resumes),
                'total_calls': int(total_calls)
            },
            'cost_usd': 0.00,  # FREE!
            'rate_limit_info': {
                'estimated_processing_time_minutes': round(estimated_time_minutes, 1),
                'calls_per_minute_limit': calls_per_minute,
                'recommended_batch_size': '5-10 resumes'
            },
            'advantages': [
                'Completely FREE with HuggingFace account',
                'Open source models (Mistral, Llama, etc.)',
                'No usage charges, only rate limits',
                'Privacy-focused (no data retention)',
                'Can upgrade to Pro for faster processing'
            ],
            'upgrade_option': {
                'huggingface_pro': '$9/month',
                'benefits': 'Higher rate limits, priority access, faster processing'
            },
            'note': 'FREE tier with rate limits. Upgrade to HuggingFace Pro for unlimited access.'
        }